{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предыстория\n",
    "\n",
    "Для сериализации объектов в языке `python` используется модуль [`pickle`](https://docs.python.org/3/library/pickle.html). Так с помощью этого модуля можно сохранять, например, модели машинного обучения или просто любые другие данные.\n",
    "\n",
    "В директории `sphere_data` лежат несколько файлов с `python`-объектами, сериализованными с помощью `pickle`. Каждый файл имеет следующий формат:\n",
    "* N – количество объектов в файле;\n",
    "* последовательность из N словарей (`record`).\n",
    "\n",
    "Пример формирования файла `sphere_data/part_*.pkl`:\n",
    "\n",
    "```python\n",
    "data = [...]\n",
    "\n",
    "with open('sphere_data/part_00000.pkl', 'wb') as f_out:\n",
    "    pickle.dump(len(data), f_out)\n",
    "    for record in data:\n",
    "        pickle.dump(data, f_out)\n",
    "```\n",
    "\n",
    "Каждый словарь имеет вид:\n",
    "```python\n",
    "record = {\n",
    "    'app_id': int,\n",
    "    'sequence': list,\n",
    "    'sequence_cat': list,\n",
    "    'sequence_len': int,\n",
    "    'product': int,\n",
    "    'flag': int,\n",
    "}\n",
    "```\n",
    "\n",
    "* `app_id` – некоторый идентификатор, имеющий тип `int`.\n",
    "* `sequence` – двумерный массив, внутренний массив имеет длину `sequence_len` и хранит элементы типа `float`; массив представляет собой список вложенных списков (`list`).\n",
    "* `sequence_cat` – двумерный массив, аналогичный `sequence`, хранит элементы типа `int`;\n",
    "* `sequence_len` – длина вложенных списков: `len(sequence[0]) == len(sequence_cat[0]) == sequence_len`.\n",
    "* `product` и `flag` – некоторые категориальные переменные типа `int`.\n",
    "\n",
    "Чтобы считать объект из файла используйте `pickle.load`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "В данном задании требуется написать генератор\n",
    "```python\n",
    "def app_records(path='sphere_data', shuffle=False, random_state=None, chunk_size=100, max_sequence_len=750):\n",
    "    pass\n",
    "```\n",
    "\n",
    "Генератор `app_records` может представлять собой генератор функцию или быть классом, реализующим механизм итерации. Вы можете выбрать наиболее удобный вариант для вас.\n",
    "\n",
    "### Пункт 1. Основная логика\n",
    "\n",
    "Генератор должен зачитывать данные из файлов, лежащих в директории `path`. Гарантируется, что все файлы в директории будут иметь формат, описанный выше и будут называться аналогично: `part_[0-9]{5}.pkl`. \n",
    "\n",
    "В случае, если `shuffle=False` требуется осортировать все файлы в директории `path` в лексикографическом порядке и отдавать по одной записи из каждого файла. Если очередной файл закончился, требуется открыть следующий файл, и начать отдавать данные из него.\n",
    "\n",
    "Таким образом, с помощью, например, вот такого кода можно получить все записи из файлов в исходном порядке:\n",
    "```python\n",
    "reader = app_records(path='sphere_data', shuffle=False)\n",
    "for record in reader:\n",
    "    # do something with record\n",
    "```\n",
    "\n",
    "### Пункт 2. Перемешивание\n",
    "\n",
    "Генератор должен уметь перемешивать порядок записей. В общем случае содержимое всех файлов может быть достаточно большим, что не поместится в оперативную память компьютера. В связи с этим предлагается реализовать следующий алгоритм псевдо-перемешивания:\n",
    "* перемешиваем файлы (порядок, в котором будем их обрабатывать);\n",
    "* считываем из перемешанных файлов `chunk_size` записей;\n",
    "* перемешиваем считанные записи.\n",
    "\n",
    "Далее генератор по-прежнему отдает записи по одной.\n",
    "\n",
    "Для воспроизводимости результата перемешивания нужно использовать аргумент `random_state` (начальный seed). Для перемешивания лучше использовать модуль [`random`](https://docs.python.org/3/library/random.html), но допускается использование модуля [`numpy.random`](https://numpy.org/doc/stable/reference/random/index.html).\n",
    "\n",
    "### Пункт 3.  Паддинг\n",
    "\n",
    "Генератор должен делать паддинг для массивов `sequence` и `sequence_cat` (дополнение нулями), если длина вложенного списка меньше, чем `max_sequence_len`: `len(sequence[0]) < max_sequence_len`.\n",
    "\n",
    "Пример:\n",
    "\n",
    "```python\n",
    "sequence = [\n",
    "    [0, 3, 3, 1, 3, 1],\n",
    "    [4, 3, 4, 3, 2, 3],\n",
    "    [2, 0, 0, 3, 3, 2],\n",
    "]\n",
    "\n",
    "assert np.asarray(sequence).shape == (3, 6)\n",
    "assert sequence_len == 6\n",
    "assert max_sequence_len == 10\n",
    "```\n",
    "\n",
    "Тогда паддинг для массива `sequence` должен выглядеть как:\n",
    "\n",
    "```python\n",
    "sequence = [\n",
    "    [0, 3, 3, 1, 3, 1, 0, 0, 0, 0],\n",
    "    [4, 3, 4, 3, 2, 3, 0, 0, 0, 0],\n",
    "    [2, 0, 0, 3, 3, 2, 0, 0, 0, 0],\n",
    "]\n",
    "\n",
    "assert np.assaray(sequence).shape == (3, 10)\n",
    "```\n",
    "\n",
    "Если `len(sequence[0]) > max_sequence_len`, то нужно обрезать массив до `max_sequence_len`.\n",
    "\n",
    "Пример:\n",
    "\n",
    "```python\n",
    "sequence = [\n",
    "    [0, 3, 3, 1, 3, 1],\n",
    "    [4, 3, 4, 3, 2, 3],\n",
    "    [2, 0, 0, 3, 3, 2],\n",
    "]\n",
    "\n",
    "assert np.asarray(sequence).shape == (3, 6)\n",
    "assert sequence_len == 6\n",
    "assert max_sequence_len == 4\n",
    "```\n",
    "\n",
    "Тогда обрезанный для массив `sequence` должен выглядеть как:\n",
    "\n",
    "```python\n",
    "sequence = [\n",
    "    [0, 3, 3, 1],\n",
    "    [4, 3, 4, 3],\n",
    "    [2, 0, 0, 3],\n",
    "]\n",
    "\n",
    "assert np.assaray(sequence).shape == (3, 4)\n",
    "```\n",
    "\n",
    "В этом пункте обязательно использовать библиотеку `numpy` для работы с формой массива. Результат применения паддинга или обрезания массива должен быть `np.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "from os import listdir\n",
    "from os.path import isfile, join, getsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает список непустых файлов с подходящими именами\n",
    "def get_files(path):\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "    cmp = re.compile('part_[0-9]{5}.pkl')\n",
    "    return sorted([f for f in files if cmp.match(f) and getsize(join(path, f))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генератор - возвращает списки по count_of_records(или максимально возможное число) записей  \n",
    "def get_records(path, count_of_records, shuffle=False):\n",
    "    batch = [] \n",
    "    files = get_files(path)\n",
    "    \n",
    "    if count_of_records < 0:\n",
    "        count_of_records = 100\n",
    "    \n",
    "    # перемешивание файлов\n",
    "    if shuffle:\n",
    "        random.shuffle(files)\n",
    "        \n",
    "    for file in get_files(path):\n",
    "        loaded = 0\n",
    "        with open(join(path, file), 'rb') as f:\n",
    "            f_size  = pickle.load(f)\n",
    "            while loaded < f_size:\n",
    "                if len(batch) < count_of_records:\n",
    "                    batch.append(pickle.load(f))\n",
    "                    loaded += 1\n",
    "                else:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "    if batch:\n",
    "        yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(record, max_len):\n",
    "    if max_len < 0:\n",
    "        return\n",
    "    if record['sequence_len'] < max_len:\n",
    "        record['sequence'] = np.pad(np.array(record['sequence']), \\\n",
    "                                    [(0, 0), (0, max_len - record['sequence_len'])], mode='constant') \n",
    "        record['sequence_cat'] = np.pad(np.array(record['sequence_cat']), \\\n",
    "                                    [(0, 0), (0, max_len - record['sequence_len'])], mode='constant')\n",
    "    else:\n",
    "        record['sequence'] = np.array(record['sequence'])[:,:max_len]\n",
    "        record['sequence_cat'] = np.array(record['sequence_cat'])[:,:max_len]\n",
    "    # в задании явно не оговорена необходимость изменения sequence_len при паддинге,\n",
    "    # но это вытекает из логики работы с записями\n",
    "    record['sequence_len'] = max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app_records(path='sphere_data', shuffle=False, random_state=None, chunk_size=100, max_sequence_len=750):\n",
    "    if random_state is not None:\n",
    "        random.seed(random_state)\n",
    "    \n",
    "    if not shuffle:\n",
    "        records = get_records(path, 1)\n",
    "    else:\n",
    "        records = get_records(path, chunk_size, shuffle)\n",
    "    \n",
    "    for records_bunch in records:\n",
    "        if not shuffle:\n",
    "            add_padding(records_bunch[0], max_sequence_len)\n",
    "            yield records_bunch[0]\n",
    "        else:\n",
    "            random.shuffle(records_bunch)\n",
    "            for record in records_bunch:\n",
    "                add_padding(record, max_sequence_len)\n",
    "                yield record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some tests..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['part_00001.pkl',\n",
       " 'part_00002.pkl',\n",
       " 'part_00003.pkl',\n",
       " 'part_00004.pkl',\n",
       " 'part_00005.pkl',\n",
       " 'part_00006.pkl',\n",
       " 'part_00007.pkl',\n",
       " 'part_00008.pkl',\n",
       " 'part_00009.pkl']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_files('sphere_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_a():\n",
    "    a=dict()\n",
    "    a['sequence'] = [[2.0, 2.0, 2.0], [2.0, 2.0, 2.0], [2.0, 2.0, 2.0]]\n",
    "    a['sequence_cat'] = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]\n",
    "    a['sequence_len'] = 3\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "{'sequence': array([[2., 2., 2., 0., 0., 0., 0.],\n",
      "       [2., 2., 2., 0., 0., 0., 0.],\n",
      "       [2., 2., 2., 0., 0., 0., 0.]]), 'sequence_cat': array([[1, 1, 1, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 0, 0, 0, 0],\n",
      "       [1, 1, 1, 0, 0, 0, 0]]), 'sequence_len': 7}\n"
     ]
    }
   ],
   "source": [
    "a = get_a()\n",
    "add_padding(a, 7)\n",
    "print(type(a['sequence']))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "{'sequence': array([[2., 2.],\n",
      "       [2., 2.],\n",
      "       [2., 2.]]), 'sequence_cat': array([[1, 1],\n",
      "       [1, 1],\n",
      "       [1, 1]]), 'sequence_len': 2}\n"
     ]
    }
   ],
   "source": [
    "a = get_a()\n",
    "add_padding(a, 2)\n",
    "print(type(a['sequence']))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "{'sequence': [[2.0, 2.0, 2.0], [2.0, 2.0, 2.0], [2.0, 2.0, 2.0]], 'sequence_cat': [[1, 1, 1], [1, 1, 1], [1, 1, 1]], 'sequence_len': 3}\n"
     ]
    }
   ],
   "source": [
    "a = get_a()\n",
    "add_padding(a, -56)\n",
    "print(type(a['sequence']))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "число записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = app_records(path='sphere_data')\n",
    "cnt = 0\n",
    "for record in reader:\n",
    "    cnt += 1\n",
    "assert cnt==9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = app_records(path='sphere_data', shuffle=True)\n",
    "cnt = 0\n",
    "for record in reader:\n",
    "    cnt += 1\n",
    "assert cnt==9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = app_records(path='sphere_data', shuffle=True, chunk_size=89)\n",
    "cnt = 0\n",
    "for record in reader:\n",
    "    cnt += 1\n",
    "assert cnt==9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = app_records(path='sphere_data', shuffle=True, chunk_size=129)\n",
    "cnt = 0\n",
    "for record in reader:\n",
    "    cnt += 1\n",
    "assert cnt==9000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = app_records(path='sphere_data', shuffle=True, random_state=42)\n",
    "cnt = 0\n",
    "for record in reader:\n",
    "    cnt += 1\n",
    "    if cnt==5678:\n",
    "        r1 = record\n",
    "\n",
    "reader = app_records(path='sphere_data', shuffle=True, random_state=42)\n",
    "cnt = 0\n",
    "for record in reader:\n",
    "    cnt += 1\n",
    "    if cnt==5678:\n",
    "        r2 = record\n",
    "assert (r1['sequence']==r2['sequence']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "без random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = app_records(path='sphere_data', shuffle=True)\n",
    "cnt = 0\n",
    "for record in reader:\n",
    "    cnt += 1\n",
    "    if cnt==5678:\n",
    "        r1 = record\n",
    "\n",
    "reader = app_records(path='sphere_data', shuffle=True)\n",
    "cnt = 0\n",
    "for record in reader:\n",
    "    cnt += 1\n",
    "    if cnt==5678:\n",
    "        r2 = record\n",
    "\n",
    "assert (r1['sequence']!=r2['sequence']).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
